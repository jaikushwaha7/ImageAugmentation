<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Computer Vision Mentorship Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
            padding: 40px 0;
        }

        .header h1 {
            font-size: 3em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .progress-bar {
            width: 100%;
            height: 6px;
            background: rgba(255,255,255,0.3);
            border-radius: 3px;
            margin: 20px 0;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #45a049);
            width: 0%;
            transition: width 0.3s ease;
        }

        .nav-tabs {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 30px;
            justify-content: center;
        }

        .nav-tab {
            padding: 12px 20px;
            background: rgba(255,255,255,0.9);
            border: none;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 500;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .nav-tab:hover {
            background: white;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0,0,0,0.2);
        }

        .nav-tab.active {
            background: #4CAF50;
            color: white;
        }

        .content-section {
            display: none;
            background: white;
            border-radius: 20px;
            padding: 40px;
            margin-bottom: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            animation: fadeIn 0.5s ease-in;
        }

        .content-section.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        h2 {
            color: #2c3e50;
            margin-bottom: 20px;
            font-size: 2.2em;
            border-bottom: 3px solid #4CAF50;
            padding-bottom: 10px;
        }

        h3 {
            color: #34495e;
            margin: 25px 0 15px 0;
            font-size: 1.5em;
        }

        .concept-box {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 20px 0;
            border-left: 5px solid #4CAF50;
            position: relative;
            overflow: hidden;
        }

        .concept-box::before {
            content: '';
            position: absolute;
            top: 0;
            right: 0;
            width: 100px;
            height: 100px;
            background: radial-gradient(circle, rgba(76,175,80,0.1) 0%, transparent 70%);
        }

        .interactive-demo {
            background: #f8f9fa;
            border: 2px dashed #4CAF50;
            border-radius: 15px;
            padding: 30px;
            margin: 25px 0;
            text-align: center;
        }

        .demo-controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
            margin: 20px 0;
        }

        .btn {
            padding: 12px 25px;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.3s ease;
            background: linear-gradient(135deg, #4CAF50, #45a049);
            color: white;
            box-shadow: 0 4px 15px rgba(76,175,80,0.3);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(76,175,80,0.4);
        }

        .btn-secondary {
            background: linear-gradient(135deg, #6c757d, #5a6268);
            box-shadow: 0 4px 15px rgba(108,117,125,0.3);
        }

        .canvas-container {
            display: flex;
            justify-content: center;
            margin: 20px 0;
            gap: 20px;
            flex-wrap: wrap;
        }

        canvas {
            border: 2px solid #ddd;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .slider-container {
            margin: 20px 0;
        }

        .slider {
            width: 100%;
            height: 6px;
            border-radius: 3px;
            background: #ddd;
            outline: none;
            -webkit-appearance: none;
        }

        .slider::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: #4CAF50;
            cursor: pointer;
            box-shadow: 0 2px 6px rgba(0,0,0,0.2);
        }

        .quiz-container {
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            padding: 25px;
            border-radius: 15px;
            margin: 25px 0;
        }

        .quiz-question {
            font-weight: 600;
            margin-bottom: 15px;
            font-size: 1.1em;
        }

        .quiz-options {
            display: grid;
            gap: 10px;
            margin: 15px 0;
        }

        .quiz-option {
            padding: 12px 20px;
            background: white;
            border: 2px solid transparent;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .quiz-option:hover {
            border-color: #4CAF50;
            transform: translateX(5px);
        }

        .quiz-option.correct {
            background: #d4edda;
            border-color: #28a745;
        }

        .quiz-option.incorrect {
            background: #f8d7da;
            border-color: #dc3545;
        }

        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 10px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            position: relative;
        }

        .code-block::before {
            content: 'Python';
            position: absolute;
            top: 5px;
            right: 10px;
            font-size: 0.8em;
            color: #a0aec0;
        }

        .highlight {
            background: linear-gradient(120deg, rgba(255,255,0,0.3) 0%, rgba(255,255,0,0.3) 100%);
            padding: 2px 4px;
            border-radius: 3px;
        }

        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .image-placeholder {
            aspect-ratio: 1;
            background: linear-gradient(45deg, #f0f0f0 25%, transparent 25%), 
                        linear-gradient(-45deg, #f0f0f0 25%, transparent 25%), 
                        linear-gradient(45deg, transparent 75%, #f0f0f0 75%), 
                        linear-gradient(-45deg, transparent 75%, #f0f0f0 75%);
            background-size: 20px 20px;
            background-position: 0 0, 0 10px, 10px -10px, -10px 0px;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #666;
            font-weight: 500;
            border: 2px dashed #ccc;
        }

        .metrics-display {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }

        .metric-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border-left: 4px solid #4CAF50;
        }

        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #4CAF50;
        }

        .metric-label {
            color: #666;
            font-size: 0.9em;
            margin-top: 5px;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .header h1 {
                font-size: 2em;
            }
            
            .content-section {
                padding: 20px;
            }
            
            .demo-controls {
                flex-direction: column;
                align-items: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéØ Computer Vision Mentorship Guide</h1>
            <p>Master Image Augmentation, Fine-Tuning, and Object Detection</p>
            <div class="progress-bar">
                <div class="progress-fill" id="progressFill"></div>
            </div>
        </div>

        <div class="nav-tabs">
            <button class="nav-tab active" onclick="showSection('augmentation')">14.1 Image Augmentation</button>
            <button class="nav-tab" onclick="showSection('finetuning')">14.2 Fine-Tuning</button>
            <button class="nav-tab" onclick="showSection('detection')">14.3 Object Detection</button>
            <button class="nav-tab" onclick="showSection('anchors')">14.4 Anchor Boxes</button>
            <button class="nav-tab" onclick="showSection('multiscale')">14.5 Multiscale Detection</button>
            <button class="nav-tab" onclick="showSection('dataset')">14.6 Dataset Handling</button>
            <button class="nav-tab" onclick="showSection('ssd')">14.7 SSD Model</button>
        </div>

        <!-- 14.5 Multiscale Detection -->
        <div id="multiscale" class="content-section">
            <h2>14.5 Multiscale Object Detection</h2>
            
            <div class="concept-box">
                <h3>üîç Why Multiscale Detection?</h3>
                <p>Objects appear at different sizes in images. Multiscale detection uses feature maps at different resolutions to detect objects of various sizes effectively.</p>
            </div>

            <h3>14.5.1 Multiscale Anchor Boxes</h3>
            
            <div class="interactive-demo">
                <h4>üìè Multiscale Visualization</h4>
                <div class="canvas-container">
                    <canvas id="scale1Canvas" width="150" height="150"></canvas>
                    <canvas id="scale2Canvas" width="150" height="150"></canvas>
                    <canvas id="scale3Canvas" width="150" height="150"></canvas>
                </div>
                <div class="demo-controls">
                    <button class="btn" onclick="showSmallObjects()">üê≠ Small Objects</button>
                    <button class="btn" onclick="showMediumObjects()">üê± Medium Objects</button>
                    <button class="btn" onclick="showLargeObjects()">üêò Large Objects</button>
                    <button class="btn" onclick="showAllScales()">üåê All Scales</button>
                </div>
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value" id="smallDetections">0</div>
                        <div class="metric-label">Small Objects</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="mediumDetections">0</div>
                        <div class="metric-label">Medium Objects</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="largeDetections">0</div>
                        <div class="metric-label">Large Objects</div>
                    </div>
                </div>
            </div>

            <div class="code-block">
# Feature Pyramid Network for multiscale detection
class FPN(nn.Module):
    def __init__(self, backbone):
        super(FPN, self).__init__()
        self.backbone = backbone
        
        # Lateral connections
        self.lateral_conv1 = nn.Conv2d(2048, 256, 1)
        self.lateral_conv2 = nn.Conv2d(1024, 256, 1)
        self.lateral_conv3 = nn.Conv2d(512, 256, 1)
        
        # Output convolutions
        self.output_conv1 = nn.Conv2d(256, 256, 3, padding=1)
        self.output_conv2 = nn.Conv2d(256, 256, 3, padding=1)
        self.output_conv3 = nn.Conv2d(256, 256, 3, padding=1)
    
    def forward(self, x):
        # Extract features at different scales
        c3, c4, c5 = self.backbone(x)
        
        # Top-down pathway
        p5 = self.lateral_conv1(c5)
        p4 = self.lateral_conv2(c4) + F.upsample(p5, scale_factor=2)
        p3 = self.lateral_conv3(c3) + F.upsample(p4, scale_factor=2)
        
        # Apply output convolutions
        p3 = self.output_conv3(p3)
        p4 = self.output_conv2(p4)
        p5 = self.output_conv1(p5)
        
        return [p3, p4, p5]
            </div>

            <h3>14.5.2 Multiscale Detection</h3>
            
            <div class="quiz-container">
                <div class="quiz-question">üß† Which feature map is best for detecting small objects?</div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="checkAnswer(this, false)">A) Deep, low-resolution feature maps</div>
                    <div class="quiz-option" onclick="checkAnswer(this, true)">B) Shallow, high-resolution feature maps</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only the final feature map</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">D) Feature maps don't matter</div>
                </div>
            </div>

            <h3>14.5.3 Summary</h3>
            <div class="concept-box">
                <p><span class="highlight">Multiscale Benefits:</span></p>
                <ul>
                    <li>Detects objects across different size ranges</li>
                    <li>Combines semantic and spatial information</li>
                    <li>Improves small object detection accuracy</li>
                    <li>Enables efficient single-shot detection</li>
                </ul>
            </div>
        </div>

        <!-- 14.6 Dataset Handling -->
        <div id="dataset" class="content-section">
            <h2>14.6 The Object Detection Dataset</h2>
            
            <div class="concept-box">
                <h3>üìä Dataset Structure</h3>
                <p>Object detection datasets contain images with corresponding annotations that specify object locations and classes. Proper dataset handling is crucial for training effective models.</p>
            </div>

            <h3>14.6.1 Downloading the Dataset</h3>
            
            <div class="interactive-demo">
                <h4>üì• Dataset Download Simulator</h4>
                <div class="progress-bar">
                    <div class="progress-fill" id="downloadProgress"></div>
                </div>
                <div class="demo-controls">
                    <button class="btn" onclick="simulateDownload()">üì• Start Download</button>
                    <button class="btn" onclick="validateDataset()">‚úÖ Validate Dataset</button>
                    <button class="btn btn-secondary" onclick="resetDownload()">üîÑ Reset</button>
                </div>
                <div id="downloadStatus">Ready to download...</div>
            </div>

            <div class="code-block">
import torchvision.datasets as datasets
from torch.utils.data import DataLoader

# Download COCO dataset
def download_coco_dataset():
    train_dataset = datasets.CocoDetection(
        root='./data/coco/train2017',
        annFile='./data/coco/annotations/instances_train2017.json',
        transform=transform
    )
    
    val_dataset = datasets.CocoDetection(
        root='./data/coco/val2017',
        annFile='./data/coco/annotations/instances_val2017.json',
        transform=transform
    )
    
    return train_dataset, val_dataset
            </div>

            <h3>14.6.2 Reading the Dataset</h3>
            
            <div class="interactive-demo">
                <h4>üìñ Dataset Explorer</h4>
                <div class="image-grid">
                    <div class="image-placeholder" onclick="loadSample(0)">
                        Sample 1<br>üñºÔ∏è Click to load
                    </div>
                    <div class="image-placeholder" onclick="loadSample(1)">
                        Sample 2<br>üñºÔ∏è Click to load
                    </div>
                    <div class="image-placeholder" onclick="loadSample(2)">
                        Sample 3<br>üñºÔ∏è Click to load
                    </div>
                    <div class="image-placeholder" onclick="loadSample(3)">
                        Sample 4<br>üñºÔ∏è Click to load
                    </div>
                </div>
                <div id="sampleInfo">
                    <div class="metrics-display">
                        <div class="metric-card">
                            <div class="metric-value" id="numObjects">0</div>
                            <div class="metric-label">Objects</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value" id="numClasses">0</div>
                            <div class="metric-label">Classes</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value" id="imageSize">0x0</div>
                            <div class="metric-label">Image Size</div>
                        </div>
                    </div>
                </div>
            </div>

            <h3>14.6.3 Demonstration</h3>
            
            <div class="code-block">
class DetectionDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, annotation_file, transform=None):
        self.image_dir = image_dir
        self.annotations = self.load_annotations(annotation_file)
        self.transform = transform
    
    def __len__(self):
        return len(self.annotations)
    
    def __getitem__(self, idx):
        # Load image
        image_path = os.path.join(self.image_dir, self.annotations[idx]['filename'])
        image = Image.open(image_path).convert('RGB')
        
        # Load annotations
        boxes = self.annotations[idx]['boxes']  # [x_min, y_min, x_max, y_max]
        labels = self.annotations[idx]['labels']
        
        if self.transform:
            image, boxes = self.transform(image, boxes)
        
        return image, {'boxes': boxes, 'labels': labels}
            </div>

            <h3>14.6.4 Summary</h3>
            <div class="concept-box">
                <p><span class="highlight">Dataset Best Practices:</span></p>
                <ul>
                    <li>Ensure consistent annotation format</li>
                    <li>Validate data integrity before training</li>
                    <li>Use appropriate data augmentation</li>
                    <li>Balance class distribution when possible</li>
                </ul>
            </div>
        </div>

        <!-- 14.7 SSD Model -->
        <div id="ssd" class="content-section">
            <h2>14.7 Single Shot Multibox Detection (SSD)</h2>
            
            <div class="concept-box">
                <h3>üéØ SSD Architecture</h3>
                <p>SSD is a popular object detection architecture that performs detection in a single forward pass. It uses multiple feature maps at different scales to detect objects of various sizes.</p>
            </div>

            <h3>14.7.1 Model</h3>
            
            <div class="interactive-demo">
                <h4>üèóÔ∏è SSD Architecture Visualizer</h4>
                <canvas id="ssdCanvas" width="600" height="300"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="showBackbone()">üîß Backbone</button>
                    <button class="btn" onclick="showFeatureMaps()">üó∫Ô∏è Feature Maps</button>
                    <button class="btn" onclick="showDetectionHeads()">üéØ Detection Heads</button>
                    <button class="btn" onclick="showFullArchitecture()">üèõÔ∏è Full Architecture</button>
                </div>
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value" id="numFeatureMaps">6</div>
                        <div class="metric-label">Feature Maps</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="numAnchors">8732</div>
                        <div class="metric-label">Total Anchors</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="numClasses">21</div>
                        <div class="metric-label">Classes (VOC)</div>
                    </div>
                </div>
            </div>

            <div class="code-block">
class SSD(nn.Module):
    def __init__(self, num_classes=21):
        super(SSD, self).__init__()
        self.num_classes = num_classes
        
        # Backbone (VGG16-based)
        self.backbone = self.build_backbone()
        
        # Additional feature layers
        self.extra_layers = self.build_extra_layers()
        
        # Detection heads
        self.loc_layers = self.build_loc_layers()
        self.conf_layers = self.build_conf_layers()
        
        # Anchor boxes
        self.anchor_generator = AnchorGenerator()
    
    def forward(self, x):
        sources = []
        
        # Extract features from backbone
        for layer in self.backbone:
            x = layer(x)
            if isinstance(layer, nn.MaxPool2d):
                sources.append(x)
        
        # Extract features from extra layers
        for layer in self.extra_layers:
            x = layer(x)
            sources.append(x)
        
        # Apply detection heads
        locations = []
        confidences = []
        
        for i, source in enumerate(sources):
            loc = self.loc_layers[i](source)
            conf = self.conf_layers[i](source)
            
            locations.append(loc.permute(0, 2, 3, 1).contiguous())
            confidences.append(conf.permute(0, 2, 3, 1).contiguous())
        
        return locations, confidences
            </div>

            <h3>14.7.2 Training</h3>
            
            <div class="interactive-demo">
                <h4>üìà Training Progress Simulator</h4>
                <canvas id="trainingCanvas" width="400" height="200"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="startTraining()">üöÄ Start Training</button>
                    <button class="btn" onclick="pauseTraining()">‚è∏Ô∏è Pause</button>
                    <button class="btn btn-secondary" onclick="resetTraining()">üîÑ Reset</button>
                </div>
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value" id="currentEpoch">0</div>
                        <div class="metric-label">Epoch</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="trainingLoss">0.00</div>
                        <div class="metric-label">Training Loss</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="validationMAP">0.00</div>
                        <div class="metric-label">Validation mAP</div>
                    </div>
                </div>
            </div>

            <div class="code-block">
# SSD Loss Function
class SSDLoss(nn.Module):
    def __init__(self, num_classes, alpha=1.0, neg_pos_ratio=3):
        super(SSDLoss, self).__init__()
        self.num_classes = num_classes
        self.alpha = alpha
        self.neg_pos_ratio = neg_pos_ratio
        
    def forward(self, predictions, targets):
        loc_preds, conf_preds = predictions
        
        # Localization loss (Smooth L1)
        pos_mask = targets['pos_mask']
        loc_loss = F.smooth_l1_loss(
            loc_preds[pos_mask], 
            targets['loc_targets'][pos_mask],
            reduction='sum'
        )
        
        # Confidence loss (Cross Entropy with Hard Negative Mining)
        conf_loss = self.hard_negative_mining(conf_preds, targets['conf_targets'])
        
        # Total loss
        num_pos = pos_mask.sum()
        total_loss = (loc_loss + self.alpha * conf_loss) / num_pos
        
        return total_loss
            </code>

            <h3>14.7.3 Prediction</h3>
            
            <div class="interactive-demo">
                <h4>üîç Inference Demo</h4>
                <canvas id="inferenceCanvas" width="300" height="200"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="runInference()">üîç Run Detection</button>
                    <button class="btn" onclick="adjustThreshold()">‚öñÔ∏è Adjust Threshold</button>
                    <button class="btn btn-secondary" onclick="clearInference()">üßπ Clear</button>
                </div>
                <div class="slider-container">
                    <label>Confidence Threshold:</label>
                    <input type="range" class="slider" id="confidenceThreshold" min="0" max="100" value="50" onchange="updateConfidenceThreshold()">
                    <span id="confidenceValue">0.50</span>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">üß† What makes SSD "single shot"?</div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="checkAnswer(this, false)">A) It only detects one object</div>
                    <div class="quiz-option" onclick="checkAnswer(this, true)">B) It performs detection in one forward pass</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">C) It uses only one feature map</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">D) It has one detection head</div>
                </div>
            </div>

            <h3>14.7.4 Summary</h3>
            <div class="concept-box">
                <p><span class="highlight">SSD Key Features:</span></p>
                <ul>
                    <li>Single forward pass for detection</li>
                    <li>Multiple feature maps for multiscale detection</li>
                    <li>Anchor-based detection approach</li>
                    <li>Good balance between speed and accuracy</li>
                </ul>
            </div>
        </div>
    </div>

    <script>
        // Global variables for interactive demos
        let currentSection = 'augmentation';
        let completedSections = [];
        let augmentationIntensity = 50;
        let finetuningStep = 1;
        let boundingBoxes = [];
        let anchorBoxes = [];
        let detections = [];
        let nmsThreshold = 0.5;
        let trainingInProgress = false;
        let trainingData = [];

        // Navigation and progress tracking
        function showSection(sectionId) {
            // Hide all sections
            document.querySelectorAll('.content-section').forEach(section => {
                section.classList.remove('active');
            });
            
            // Remove active class from all tabs
            document.querySelectorAll('.nav-tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // Show selected section
            document.getElementById(sectionId).classList.add('active');
            event.target.classList.add('active');
            
            currentSection = sectionId;
            updateProgress();
        }

        function updateProgress() {
            const sections = ['augmentation', 'finetuning', 'detection', 'anchors', 'multiscale', 'dataset', 'ssd'];
            const currentIndex = sections.indexOf(currentSection);
            const progress = ((currentIndex + 1) / sections.length) * 100;
            document.getElementById('progressFill').style.width = progress + '%';
        }

        // Image Augmentation Functions
        function drawOriginalImage() {
            const canvas = document.getElementById('originalCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Draw a simple house
            ctx.fillStyle = '#87CEEB';
            ctx.fillRect(0, 0, 200, 200); // Sky
            
            ctx.fillStyle = '#90EE90';
            ctx.fillRect(0, 150, 200, 50); // Ground
            
            ctx.fillStyle = '#8B4513';
            ctx.fillRect(75, 100, 50, 50); // House body
            
            ctx.fillStyle = '#FF0000';
            ctx.beginPath();
            ctx.moveTo(70, 100);
            ctx.lineTo(100, 75);
            ctx.lineTo(130, 100);
            ctx.closePath();
            ctx.fill(); // Roof
            
            ctx.fillStyle = '#0000FF';
            ctx.fillRect(85, 120, 15, 20); // Door
            
            ctx.fillStyle = '#FFFF00';
            ctx.fillRect(105, 115, 10, 10); // Window
        }

        function applyRotation() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            const angle = (augmentationIntensity / 100) * Math.PI / 6; // Max 30 degrees
            ctx.save();
            ctx.translate(100, 100);
            ctx.rotate(angle);
            ctx.translate(-100, -100);
            
            drawSimpleShape(ctx);
            ctx.restore();
        }

        function applyFlip() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            ctx.save();
            ctx.scale(-1, 1);
            ctx.translate(-200, 0);
            
            drawSimpleShape(ctx);
            ctx.restore();
        }

        function applyBrightness() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            const brightness = augmentationIntensity / 100;
            ctx.save();
            ctx.globalAlpha = brightness;
            
            drawSimpleShape(ctx);
            ctx.restore();
        }

        function applyCrop() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            const cropSize = 50 + (augmentationIntensity / 100) * 100;
            ctx.save();
            ctx.beginPath();
            ctx.rect(50, 50, cropSize, cropSize);
            ctx.clip();
            
            drawSimpleShape(ctx);
            ctx.restore();
        }

        function applyNoise() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            drawSimpleShape(ctx);
            
            // Add noise
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;
            const noiseLevel = augmentationIntensity / 100 * 50;
            
            for (let i = 0; i < data.length; i += 4) {
                const noise = (Math.random() - 0.5) * noiseLevel;
                data[i] = Math.max(0, Math.min(255, data[i] + noise));
                data[i + 1] = Math.max(0, Math.min(255, data[i + 1] + noise));
                data[i + 2] = Math.max(0, Math.min(255, data[i + 2] + noise));
            }
            
            ctx.putImageData(imageData, 0, 0);
        }

        function drawSimpleShape(ctx) {
            // Draw the same house as original
            ctx.fillStyle = '#87CEEB';
            ctx.fillRect(0, 0, 200, 200);
            
            ctx.fillStyle = '#90EE90';
            ctx.fillRect(0, 150, 200, 50);
            
            ctx.fillStyle = '#8B4513';
            ctx.fillRect(75, 100, 50, 50);
            
            ctx.fillStyle = '#FF0000';
            ctx.beginPath();
            ctx.moveTo(70, 100);
            ctx.lineTo(100, 75);
            ctx.lineTo(130, 100);
            ctx.closePath();
            ctx.fill();
            
            ctx.fillStyle = '#0000FF';
            ctx.fillRect(85, 120, 15, 20);
            
            ctx.fillStyle = '#FFFF00';
            ctx.fillRect(105, 115, 10, 10);
        }

        function resetImage() {
            const canvas = document.getElementById('augmentedCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            drawSimpleShape(ctx);
        }

        // Quiz functionality
        function checkAnswer(element, isCorrect) {
            // Remove previous states
            element.parentNode.querySelectorAll('.quiz-option').forEach(option => {
                option.classList.remove('correct', 'incorrect');
            });
            
            if (isCorrect) {
                element.classList.add('correct');
            } else {
                element.classList.add('incorrect');
                // Show correct answer
                element.parentNode.querySelectorAll('.quiz-option').forEach(option => {
                    if (option.onclick.toString().includes('true')) {
                        option.classList.add('correct');
                    }
                });
            }
        }

        // Fine-tuning functions
        function nextFinetuningStep() {
            if (finetuningStep < 5) {
                document.getElementById(`step${finetuningStep}`).classList.remove('active');
                finetuningStep++;
                document.getElementById(`step${finetuningStep}`).classList.add('active');
            }
        }

        function resetFinetuning() {
            document.querySelectorAll('.step').forEach(step => step.classList.remove('active'));
            finetuningStep = 1;
            document.getElementById('step1').classList.add('active');
        }

        // Hot dog classifier
        let correctPredictions = 0;
        let totalPredictions = 0;

        function classifyImage(element, actualClass) {
            totalPredictions++;
            const prediction = Math.random() > 0.3 ? actualClass : (actualClass === 'hotdog' ? 'nothotdog' : 'hotdog');
            
            if (prediction === actualClass) {
                correctPredictions++;
                element.style.backgroundColor = '#d4edda';
                element.innerHTML = '‚úÖ Correct!<br>' + (actualClass === 'hotdog' ? 'Hot Dog' : 'Not Hot Dog');
            } else {
                element.style.backgroundColor = '#f8d7da';
                element.innerHTML = '‚ùå Wrong!<br>' + (prediction === 'hotdog' ? 'Hot Dog' : 'Not Hot Dog');
            }
            
            const accuracy = (correctPredictions / totalPredictions * 100).toFixed(1);
            document.getElementById('accuracy').textContent = accuracy + '%';
            document.getElementById('predictions').textContent = totalPredictions;
        }

        // Bounding box functions
        function initializeDetectionCanvas() {
            const canvas = document.getElementById('detectionCanvas');
            if (!canvas) return;
            
            canvas.addEventListener('click', function(e) {
                const rect = canvas.getBoundingClientRect();
                const x = e.clientX - rect.left;
                const y = e.clientY - rect.top;
                
                // Add a bounding box at click location
                addBoundingBox(x - 25, y - 25, 50, 50);
            });
        }

        function addBoundingBox(x, y, width, height) {
            const canvas = document.getElementById('detectionCanvas');
            if (!canvas) return;
            
            boundingBoxes.push({x, y, width, height});
            drawBoundingBoxes();
        }

        function addRandomBox() {
            const canvas = document.getElementById('detectionCanvas');
            if (!canvas) return;
            
            const x = Math.random() * (canvas.width - 100);
            const y = Math.random() * (canvas.height - 100);
            const width = 50 + Math.random() * 100;
            const height = 50 + Math.random() * 100;
            
            addBoundingBox(x, y, width, height);
        }

        function drawBoundingBoxes() {
            const canvas = document.getElementById('detectionCanvas');
            if (!canvas) return;
            
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Draw background
            ctx.fillStyle = '#f0f0f0';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            // Draw bounding boxes
            boundingBoxes.forEach((box, index) => {
                ctx.strokeStyle = index === 0 ? '#FF0000' : '#00FF00';
                ctx.lineWidth = 2;
                ctx.strokeRect(box.x, box.y, box.width, box.height);
                
                ctx.fillStyle = index === 0 ? '#FF0000' : '#00FF00';
                ctx.font = '12px Arial';
                ctx.fillText(`Box ${index + 1}`, box.x, box.y - 5);
            });
        }

        function calculateIoU() {
            if (boundingBoxes.length < 2) {
                alert('Please add at least 2 bounding boxes to calculate IoU');
                return;
            }
            
            const box1 = boundingBoxes[0];
            const box2 = boundingBoxes[1];
            
            const intersection = calculateIntersection(box1, box2);
            const union = (box1.width * box1.height) + (box2.width * box2.height) - intersection;
            const iou = intersection / union;
            
            document.getElementById('boxInfo').innerHTML = `
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value">${iou.toFixed(3)}</div>
                        <div class="metric-label">IoU</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value">${intersection.toFixed(0)}</div>
                        <div class="metric-label">Intersection</div>
                    </div>
                    <div1 Image Augmentation -->
        <div id="augmentation" class="content-section active">
            <h2>14.1 Image Augmentation</h2>
            
            <div class="concept-box">
                <h3>üîÑ What is Image Augmentation?</h3>
                <p>Image augmentation is a technique used to artificially expand training datasets by applying various transformations to existing images. This helps models generalize better and reduces overfitting.</p>
            </div>

            <h3>14.1.1 Common Image Augmentation Methods</h3>
            
            <div class="interactive-demo">
                <h4>üé® Interactive Augmentation Demo</h4>
                <div class="canvas-container">
                    <canvas id="originalCanvas" width="200" height="200"></canvas>
                    <canvas id="augmentedCanvas" width="200" height="200"></canvas>
                </div>
                
                <div class="demo-controls">
                    <button class="btn" onclick="applyRotation()">üîÑ Rotation</button>
                    <button class="btn" onclick="applyFlip()">üîÉ Flip</button>
                    <button class="btn" onclick="applyBrightness()">‚òÄÔ∏è Brightness</button>
                    <button class="btn" onclick="applyCrop()">‚úÇÔ∏è Crop</button>
                    <button class="btn" onclick="applyNoise()">üìä Noise</button>
                    <button class="btn btn-secondary" onclick="resetImage()">üîÑ Reset</button>
                </div>

                <div class="slider-container">
                    <label>Augmentation Intensity:</label>
                    <input type="range" class="slider" id="intensitySlider" min="0" max="100" value="50">
                    <span id="intensityValue">50%</span>
                </div>
            </div>

            <div class="code-block">
import torch
import torchvision.transforms as transforms

# Define augmentation pipeline
augmentation_pipeline = transforms.Compose([
    transforms.RandomRotation(degrees=15),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomCrop(224, padding=4),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# Apply to dataset
augmented_dataset = ImageFolder(root='data/', transform=augmentation_pipeline)
            </div>

            <h3>14.1.2 Training with Image Augmentation</h3>
            
            <div class="concept-box">
                <p><span class="highlight">Key Benefits:</span></p>
                <ul>
                    <li>Increases dataset size without collecting new data</li>
                    <li>Improves model robustness to variations</li>
                    <li>Reduces overfitting</li>
                    <li>Better generalization to real-world scenarios</li>
                </ul>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">üß† Quick Quiz: Which augmentation would be most helpful for a medical imaging task?</div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="checkAnswer(this, false)">A) Heavy color distortion</div>
                    <div class="quiz-option" onclick="checkAnswer(this, true)">B) Slight rotation and zoom</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">C) Random cropping</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">D) Extreme brightness changes</div>
                </div>
            </div>

            <h3>14.1.3 Summary</h3>
            <div class="metrics-display">
                <div class="metric-card">
                    <div class="metric-value">5-10x</div>
                    <div class="metric-label">Dataset Size Increase</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">15-25%</div>
                    <div class="metric-label">Accuracy Improvement</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">50%+</div>
                    <div class="metric-label">Overfitting Reduction</div>
                </div>
            </div>
        </div>

        <!-- 14.2 Fine-Tuning -->
        <div id="finetuning" class="content-section">
            <h2>14.2 Fine-Tuning</h2>
            
            <div class="concept-box">
                <h3>üéØ Transfer Learning & Fine-Tuning</h3>
                <p>Fine-tuning leverages pre-trained models and adapts them to new tasks. Instead of training from scratch, we start with learned features and adjust them for our specific problem.</p>
            </div>

            <h3>14.2.1 Steps</h3>
            
            <div class="interactive-demo">
                <h4>üîß Fine-Tuning Process Simulator</h4>
                <div id="finetuningSteps">
                    <div class="step-indicator">
                        <div class="step active" id="step1">1. Load Pre-trained Model</div>
                        <div class="step" id="step2">2. Freeze Base Layers</div>
                        <div class="step" id="step3">3. Replace Classifier</div>
                        <div class="step" id="step4">4. Train with Low LR</div>
                        <div class="step" id="step5">5. Unfreeze & Train</div>
                    </div>
                </div>
                <button class="btn" onclick="nextFinetuningStep()">Next Step ‚Üí</button>
                <button class="btn btn-secondary" onclick="resetFinetuning()">Reset</button>
            </div>

            <div class="code-block">
import torchvision.models as models
import torch.nn as nn

# Step 1: Load pre-trained model
model = models.resnet50(pretrained=True)

# Step 2: Freeze base layers
for param in model.parameters():
    param.requires_grad = False

# Step 3: Replace classifier
num_classes = 2  # Hot dog vs Not hot dog
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Step 4: Train with low learning rate
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)
            </div>

            <h3>14.2.2 Hot Dog Recognition</h3>
            
            <div class="interactive-demo">
                <h4>üå≠ Hot Dog Classifier Demo</h4>
                <div class="image-grid">
                    <div class="image-placeholder" onclick="classifyImage(this, 'hotdog')">
                        üå≠<br>Click to classify
                    </div>
                    <div class="image-placeholder" onclick="classifyImage(this, 'nothotdog')">
                        üçï<br>Click to classify
                    </div>
                    <div class="image-placeholder" onclick="classifyImage(this, 'hotdog')">
                        üå≠<br>Click to classify
                    </div>
                    <div class="image-placeholder" onclick="classifyImage(this, 'nothotdog')">
                        üçî<br>Click to classify
                    </div>
                </div>
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value" id="accuracy">0%</div>
                        <div class="metric-label">Accuracy</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="predictions">0</div>
                        <div class="metric-label">Predictions Made</div>
                    </div>
                </div>
            </div>

            <div class="quiz-container">
                <div class="quiz-question">üß† When should you unfreeze all layers during fine-tuning?</div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="checkAnswer(this, false)">A) Immediately at the start</div>
                    <div class="quiz-option" onclick="checkAnswer(this, true)">B) After the new classifier converges</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">C) Never unfreeze them</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">D) Only with large datasets</div>
                </div>
            </div>

            <h3>14.2.3 Summary</h3>
            <div class="concept-box">
                <p><span class="highlight">Fine-tuning Best Practices:</span></p>
                <ul>
                    <li>Start with frozen base layers</li>
                    <li>Use lower learning rates for pre-trained layers</li>
                    <li>Gradually unfreeze layers from top to bottom</li>
                    <li>Monitor for overfitting carefully</li>
                </ul>
            </div>
        </div>

        <!-- 14.3 Object Detection -->
        <div id="detection" class="content-section">
            <h2>14.3 Object Detection and Bounding Boxes</h2>
            
            <div class="concept-box">
                <h3>üéØ Object Detection Overview</h3>
                <p>Object detection combines classification and localization. We need to identify <em>what</em> objects are in an image and <em>where</em> they are located using bounding boxes.</p>
            </div>

            <h3>14.3.1 Bounding Boxes</h3>
            
            <div class="interactive-demo">
                <h4>üì¶ Interactive Bounding Box Demo</h4>
                <canvas id="detectionCanvas" width="400" height="300" style="border: 2px solid #333; cursor: crosshair;"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="addRandomBox()">‚ûï Add Random Box</button>
                    <button class="btn" onclick="calculateIoU()">üìä Calculate IoU</button>
                    <button class="btn btn-secondary" onclick="clearBoxes()">üóëÔ∏è Clear All</button>
                </div>
                <div id="boxInfo"></div>
            </div>

            <div class="code-block">
# Bounding box representation: [x_min, y_min, x_max, y_max]
def draw_bounding_box(image, box, label, confidence):
    x_min, y_min, x_max, y_max = box
    
    # Draw rectangle
    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
    
    # Add label
    label_text = f"{label}: {confidence:.2f}"
    cv2.putText(image, label_text, (x_min, y_min-10), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    return image
            </div>

            <div class="quiz-container">
                <div class="quiz-question">üß† What information does a bounding box contain?</div>
                <div class="quiz-options">
                    <div class="quiz-option" onclick="checkAnswer(this, false)">A) Only object class</div>
                    <div class="quiz-option" onclick="checkAnswer(this, true)">B) Position and size coordinates</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">C) Only confidence score</div>
                    <div class="quiz-option" onclick="checkAnswer(this, false)">D) Color information</div>
                </div>
            </div>

            <h3>14.3.2 Summary</h3>
            <div class="metrics-display">
                <div class="metric-card">
                    <div class="metric-value">4</div>
                    <div class="metric-label">Coordinates per Box</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">0.5</div>
                    <div class="metric-label">IoU Threshold</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">‚àû</div>
                    <div class="metric-label">Objects per Image</div>
                </div>
            </div>
        </div>

        <!-- 14.4 Anchor Boxes -->
        <div id="anchors" class="content-section">
            <h2>14.4 Anchor Boxes</h2>
            
            <div class="concept-box">
                <h3>‚öì Understanding Anchor Boxes</h3>
                <p>Anchor boxes are pre-defined bounding boxes of various sizes and aspect ratios placed densely across an image. They serve as reference points for object detection algorithms.</p>
            </div>

            <h3>14.4.1 Generating Multiple Anchor Boxes</h3>
            
            <div class="interactive-demo">
                <h4>‚öì Anchor Box Generator</h4>
                <canvas id="anchorCanvas" width="400" height="300"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="generateAnchors()">üéØ Generate Anchors</button>
                    <button class="btn" onclick="showBestAnchor()">‚≠ê Show Best Match</button>
                    <button class="btn btn-secondary" onclick="clearAnchors()">üßπ Clear</button>
                </div>
                <div class="slider-container">
                    <label>Number of Scales:</label>
                    <input type="range" class="slider" id="scaleSlider" min="1" max="5" value="3" onchange="updateAnchors()">
                    <span id="scaleValue">3</span>
                </div>
                <div class="slider-container">
                    <label>Aspect Ratios:</label>
                    <input type="range" class="slider" id="ratioSlider" min="1" max="5" value="3" onchange="updateAnchors()">
                    <span id="ratioValue">3</span>
                </div>
            </div>

            <h3>14.4.2 Intersection over Union (IoU)</h3>
            
            <div class="interactive-demo">
                <h4>üìä IoU Calculator</h4>
                <div class="metrics-display">
                    <div class="metric-card">
                        <div class="metric-value" id="iouValue">0.00</div>
                        <div class="metric-label">IoU Score</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="intersectionArea">0</div>
                        <div class="metric-label">Intersection</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-value" id="unionArea">0</div>
                        <div class="metric-label">Union</div>
                    </div>
                </div>
            </div>

            <div class="code-block">
def calculate_iou(box1, box2):
    """Calculate Intersection over Union of two bounding boxes"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    # Calculate intersection
    inter_x_min = max(x1_min, x2_min)
    inter_y_min = max(y1_min, y2_min)
    inter_x_max = min(x1_max, x2_max)
    inter_y_max = min(y1_max, y2_max)
    
    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
        return 0.0
    
    intersection = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
    
    # Calculate union
    area1 = (x1_max - x1_min) * (y1_max - y1_min)
    area2 = (x2_max - x2_min) * (y2_max - y2_min)
    union = area1 + area2 - intersection
    
    return intersection / union
            </div>

            <h3>14.4.3 Labeling Anchor Boxes in Training Data</h3>
            <h3>14.4.4 Predicting Bounding Boxes with Non-Maximum Suppression</h3>
            
            <div class="interactive-demo">
                <h4>üéØ Non-Maximum Suppression Demo</h4>
                <canvas id="nmsCanvas" width="400" height="300"></canvas>
                <div class="demo-controls">
                    <button class="btn" onclick="addDetection()">‚ûï Add Detection</button>
                    <button class="btn" onclick="applyNMS()">üî• Apply NMS</button>
                    <button class="btn btn-secondary" onclick="clearDetections()">üóëÔ∏è Clear</button>
                </div>
                <div class="slider-container">
                    <label>NMS Threshold:</label>
                    <input type="range" class="slider" id="nmsThreshold" min="0" max="100" value="50" onchange="updateNMSThreshold()">
                    <span id="nmsValue">0.50</span>
                </div>
            </div>

            <h3>14.4.5 Summary</h3>
            <div class="concept-box">
                <p><span class="highlight">Key Concepts:</span></p>
                <ul>
                    <li>Anchor boxes provide reference points for detection</li>
                    <li>IoU measures overlap between predicted and ground truth boxes</li>
                    <li>NMS removes redundant detections</li>
                    <li>Multiple scales and aspect ratios improve detection</li>
                </ul>
            </div>
        </div>

        <!-- 14.